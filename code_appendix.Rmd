---
title: "Code Appendix"
output:
  pdf_document:
    fig_caption: yes
    number_sections: true
author: "Allison Cao"
---

# Setup
```{r, include=FALSE}
library(cmu.textstat)
library(tidyverse)
library(quanteda)
library(nnet)
library(udpipe)
library(ggraph)
```

# Load Corpus
```{r}
coca_sample_corpus <- list()
target_folder <- "coca-samples-split-texts"
files_list_1940s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/1940-1949", full.names = T)
files_list_1960s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/1960-1969", full.names = T)
files_list_1970s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/1970-1979", full.names = T)
files_list_1980s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/1980-1989", full.names = T)
files_list_1990s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/1990-1999", full.names = T)
files_list_2000s <- list.files("/Users/allisoncao/Documents/Fall 2022/36468/Final Project/coha-samples-text/2000-2010", full.names = T)


create_corpus <- function(files_list) {
  out <- data.frame()
  for (file in files_list) {
    text <- readChar(file, file.info(file)$size)
    text_id <- substr(file, 87, nchar(file) - 4)
    # print(text_id)
    tmp = data.frame(c(text_id), c(trimws(text)))
    # print(tmp)
    out = rbind(tmp, out)
  }
  colnames(out) = c("text_id", "text")
  return(out)
}

corpus_1940s = create_corpus(files_list_1940s) 
corpus_1960s <- create_corpus(files_list_1960s) 
corpus_1970s = create_corpus(files_list_1970s) 
corpus_1980s = create_corpus(files_list_1980s) 
corpus_1990s = create_corpus(files_list_1990s)
corpus_2000s = create_corpus(files_list_2000s)

tokens_1940 <- corpus_1940s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)
tokens_1960 <- corpus_1960s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)

tokens_1970 <- corpus_1970s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)

tokens_1980 <- corpus_1980s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)

tokens_1990 <- corpus_1990s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)

tokens_2000 <- corpus_2000s %>%
  mutate(text = preprocess_text(text)) %>%
  corpus() %>%
  tokens(what="fastestword", remove_numbers=TRUE)
```

# Data
```{r}
df <- data.frame(c("Words (Tokens)", "Files"), c(sum(ntoken(tokens_1960)), sum(ntoken(tokens_2000))), c(106, 111))
colnames(df) <- c("Subcorpus", "COHA 1960-1969", "COHA 2000-2010")
knitr::kable(df, caption = "Subcorpora used in study")

freq_df <- frequency_table(tokens_1960)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the 1960s corpus.")

freq_df <- frequency_table(tokens_1970)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the 1970s corpus.")

freq_df <- frequency_table(tokens_1980)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the 1980s corpus.")

freq_df <- frequency_table(tokens_1990)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the 1990s corpus.")

freq_df <- frequency_table(tokens_2000)
knitr::kable(freq_df[1:10,], caption = "The 10 most frequent tokens in the 2000s corpus.")
```

# Collocations
```{r}
collocates_1940 <- collocates_by_MI(tokens_1940, "terror")
collocates_1960 <- collocates_by_MI(tokens_1960, "terror")
collocates_1970 <- collocates_by_MI(tokens_1970, "terror")
collocates_1980 <- collocates_by_MI(tokens_1980, "terror")
collocates_1990 <- collocates_by_MI(tokens_1990, "terror")
collocates_2000 <- collocates_by_MI(tokens_2000, "terror")

c1940 <- collocates_1940 %>% filter(total_freq >= 10 & MI_1 >= 7)
c1960 <- collocates_1960 %>% filter(total_freq >= 10 & MI_1 >= 7)
c1970 <- collocates_1970 %>% filter(total_freq >= 10 & MI_1 >= 7)
c1980 <- collocates_1980 %>% filter(total_freq >= 10 & MI_1 >= 7)
c1990 <- collocates_1990 %>% filter(total_freq >= 10 & MI_1 >= 7)
c2000 <- collocates_2000 %>% filter(total_freq >= 10 & MI_1 >= 7)

knitr::kable(head(c1940), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 1960-1969 corpus.")
knitr::kable(head(c1960), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 1960-1969 corpus.")
knitr::kable(head(c1970), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 1970-1979 corpus.")
knitr::kable(head(c1980), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 1980-1989 corpus.")
knitr::kable(head(c1990), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 1990-1999 corpus.")
knitr::kable(head(c2000), digits = 3, caption = "The collocates with the highest MI for the token 'terror' in the 2000-2010 corpus.")
```

# Collocational Networks
```{r}
# collocational networks
net <- col_network(c1940, c1960)

ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T, size = 3) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")
```

```{r}
# collocational networks
net <- col_network(c1960, c2000)

ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T, size = 3) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")

c1960 <- collocates_1960 %>% filter(total_freq >= 10 & MI_1 >= 4)
c1980 <- collocates_1980 %>% filter(total_freq >= 10 & MI_1 >= 4)

net <- col_network(c1960, c1980)
ggraph(net, weight = link_weight, layout = "stress") + 
  geom_edge_link(color = "gray80", alpha = .75) + 
  geom_node_point(aes(alpha = node_weight, size = 3, color = n_intersects)) +
  geom_node_text(aes(label = label), repel = T, size = 3) +
  scale_alpha(range = c(0.2, 0.9)) +
  theme_graph() +
  theme(legend.position="none")
```

# Keyness Tables
```{r}
annotate_splits <- function(corpus_text) {
  ud_model <- udpipe_load_model("english-ewt-ud-2.5-191206.udpipe")
  x <- data.table::as.data.table(udpipe_annotate(ud_model, x = corpus_text$text,
                                                 doc_id = corpus_text$text_id))
  return(x)
}

annotate_corpus <- function(corpus_text) {
  # annotating
  corpus_split <- split(corpus_text, seq(1, nrow(corpus_text), by = 10))
  library(future.apply)
  ncores <- 4L
  plan(multisession, workers = ncores)
  
  
  annotation <- future_lapply(corpus_split, annotate_splits, future.seed = T)
  annotation <- data.table::rbindlist(annotation)
  anno_edit <- annotation %>%
    dplyr::select(doc_id, sentence_id, token_id, token, lemma, upos, xpos, head_token_id, dep_rel) %>%
    rename(pos = upos, tag = xpos)
  
  anno_edit <- structure(anno_edit, class = c("spacyr_parsed", "data.frame"))
  sub_tkns <- as.tokens(anno_edit, include_pos = "tag", concatenator = "_")
  doc_categories <- names(sub_tkns) %>%
    data.frame(text_type = .) %>%
    mutate(text_type = str_extract(text_type, "^[a-z]+"))
  
  docvars(sub_tkns) <- doc_categories
  sub_dfm <- dfm(sub_tkns)
  return(sub_dfm)
} 

annotate_tkns <- function(corpus_text) {
  # annotating
  corpus_split <- split(corpus_text, seq(1, nrow(corpus_text), by = 10))
  library(future.apply)
  ncores <- 4L
  plan(multisession, workers = ncores)
  
  
  annotation <- future_lapply(corpus_split, annotate_splits, future.seed = T)
  annotation <- data.table::rbindlist(annotation)
  anno_edit <- annotation %>%
    dplyr::select(doc_id, sentence_id, token_id, token, lemma, upos, xpos, head_token_id, dep_rel) %>%
    rename(pos = upos, tag = xpos)
  
  anno_edit <- structure(anno_edit, class = c("spacyr_parsed", "data.frame"))
  sub_tkns <- as.tokens(anno_edit, include_pos = "tag", concatenator = "_")
  doc_categories <- names(sub_tkns) %>%
    data.frame(text_type = .) %>%
    mutate(text_type = str_extract(text_type, "^[a-z]+"))
  
  docvars(sub_tkns) <- doc_categories
  return(sub_tkns)
} 

dfm1960 = annotate_corpus(corpus_1960s)
dfm2000 = annotate_corpus(corpus_2000s)
tkns1960 = annotate_tkns(corpus_1960s)
tkns2000 = annotate_tkns(corpus_2000s)

news_dfm <- dfm_subset(dfm1960, text_type == "news") %>% dfm_trim(min_termfreq = 1)
fic_dfm <- dfm_subset(dfm1960, text_type == "fic") %>% dfm_trim(min_termfreq = 1)

news_v_fic <- keyness_table(news_dfm, fic_dfm) %>%
  separate(col = Token, into = c("Token", "Tag"), sep = "_")

v_1960_2000 <- keyness_table(dfm1960, dfm2000) %>%
  separate(col = Token, into = c("Token", "Tag"), sep = "_")

kableExtra::kbl(news_v_fic %>% filter(Tag == "md"), caption = "A keyness comparision of modal verbs in a sub-sample of the academic vs. fiction text-types.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()

kableExtra::kbl(v_1960_2000 %>% filter(Tag == "md"), caption = "A keyness comparision of modal verbs in a sub-sample of the 1960 vs. 2000s text-types.", booktabs = T, linesep = "", digits = 2) %>%
  kableExtra::kable_styling(latex_options = "HOLD_position") %>%
  kableExtra::kable_classic()
```

# KWIC

```{r}
kwic(tkns1960, window=3, pattern="of_IN")[1:10,]
kwic(tokens_2000, window=3, pattern="of_IN")[1:10,]
```



